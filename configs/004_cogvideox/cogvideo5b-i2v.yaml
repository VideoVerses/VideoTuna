model:
  base_learning_rate: 6e-6
  target: videotuna.cogvideo_hf.cogvideo_i2v.CogVideoXI2V
  params: 
    noised_image_input: True
    noised_image_dropout: 0.05
    # VAE of CogVideoX
    first_stage_config:
      target: diffusers.AutoencoderKLCogVideoX
      params:
        pretrained_model_name_or_path: checkpoints/cogvideo/CogVideoX-5b-I2V
        subfolder: "vae"
    
    # Text encoder (T5) of CogVideoX
    cond_stage_config:
      target: videotuna.lvdm.modules.encoders.condition.FrozenT5Embedder
      params:
        version: "DeepFloyd/t5-v1_1-xxl"
        device: "cuda"
        max_length: 226 
        freeze: True
    
    # Denosier model
    denoiser_config:
      target: diffusers.CogVideoXTransformer3DModel
      params:
        pretrained_model_name_or_path: checkpoints/cogvideo/CogVideoX-5b-I2V
        subfolder: "transformer"
        load_dtype: fp16 # bf16 5b / fp16 2B 
        # revision: null 
        # variant: null
    
    # Lora module 
    adapter_config: 
      target: peft.LoraConfig
      params:
        r: 4
        lora_alpha: 1.0 
        init_lora_weights: True
        target_modules: ["to_k", "to_q", "to_v", "to_out.0"]

    # Diffusion sampling scheduler
    scheduler_config:
      target: diffusers.CogVideoXDPMScheduler
      params:
        pretrained_model_name_or_path: checkpoints/cogvideo/CogVideoX-5b-I2V
        subfolder: scheduler

# data configs
# data:
#   target: videotuna.data.lightning_data.DataModuleFromConfig
#   params:
#     batch_size: 2
#     num_workers: 16
#     wrap: false
#     train:
#       target: videotuna.data.cogvideo_dataset.VideoDataset
#       params:
#         instance_data_root: inputs/data-cartoon-talk #"inputs/t2v/cogvideo/elon_musk_video"
#         dataset_name: null 
#         dataset_config_name: null
#         caption_column: "labels.txt"
#         video_column: "videos.txt"
#         height: 480
#         width: 720
#         fps: 28
#         max_num_frames: 2
#         skip_frames_start: 0
#         skip_frames_end: 0
#         cache_dir: ~/.cache
#         id_token: null
#         image_to_video: true
data:
  target: videotuna.data.lightning_data.DataModuleFromConfig
  params:
    batch_size: 1
    num_workers: 16
    wrap: false
    train:
      target: videotuna.data.datasets.DatasetFromCSV
      params:
        csv_path: temp/apply_lipstick.csv
        height: 480
        width: 720
        video_length: 49
        frame_interval: 1
        train: True
        image_to_video: true
    validation:
      target: videotuna.data.datasets.DatasetFromCSV
      params:
        csv_path: temp/apply_lipstick.csv
        height: 480
        width: 720
        video_length: 49
        frame_interval: 1
        train: False
        image_to_video: true

# training configs
lightning:
  trainer:
    benchmark: True
    num_nodes: 1
    accumulate_grad_batches: 2
    max_epochs: 2000
    precision: 32
  callbacks:
    image_logger:
      target: videotuna.utils.callbacks.ImageLogger
      params:
        batch_frequency: 100000
        max_images: 2
        to_local: True # save videos into local files
        log_images_kwargs:
          unconditional_guidance_scale: 6
    metrics_over_trainsteps_checkpoint:
      target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        filename: "{epoch:06}-{step:09}"
        save_weights_only: False
        # every_n_epochs: 300
        every_n_train_steps: 10
    

